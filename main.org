#+TITLE: Cadenas de Markov
#+AUTHOR: Ignacio CordÃ³n Castillo
#+OPTIONS: toc:t num:3
#+STARTUP: indent
#+STARTUP: latexpreview

#+latex_class: scrreprt
#+latex_class_options: [oneside,english,openright,titlepage,numbers=noenddot,openany,headinclude,footinclude=true,cleardoublepage=empty,abstractoff,BCOR=5mm,paper=a4,fontsize=12pt,ngerman,american]
#+latex_header_extra: \definecolor{ugrColor}{HTML}{c6474b} 
#+latex_header_extra: \input{frontmatter/titlepage}\usepackage{wallpaper}\ThisULCornerWallPaper{1}{imgs/ugrA4.pdf}
#+latex_header_extra: \usepackage[T1]{fontenc}
#+latex_header_extra: \usepackage{babel}
#+latex_header_extra: \usepackage[beramono,eulerchapternumbers,linedheaders,parts,a5paper,dottedtoc,manychapters]{classicthesis}
#+latex_header_extra: \input{config/setup}
#+latex_header_extra: \input{config/classicthesis}
#+latex_header: \input{config/macros}

* Abstract
:PROPERTIES:
:UNNUMBERED: t
:END:

Markov chains are a mathematical area which encompasses probability, inference, algebra (more accurately graph theory), algorithms theory (since discrete markov chains can be simulated in a computer, and therefore, we intend to simulate them as efficiently as we can or use as big input sizes as we can, for example in markov chains with more states). All of the above conditions make markov chains an interesting study from both the mathematical and the computer science viewpoint.

* Introduction to Markov chains
** Definition
For convenience, unless otherwise indicated, we will consider $0\in \mathbb{N}$.

#+begin_definition
A stochastic random process $\{X_n\}_{n\in I}$, where $I\subseteq \mathbb{N}$, is a Markov chain iff the future process $\{X_k\}_{k > n, k \in I}$ is independent of the past process $\{X_k\}_{k < n, k \in I}$ conditionally on $X_n$.
#+end_definition

#+begin_definition
Given $\{X_n\}_{n\in I}$ a Markov chain, let us call the state space the set $S = \bigcup_{n \in I} Img \left(X_n\right)$, i.e. the set where the Markov chain takes its values.
#+end_definition

We will omit the subscript $n\in I$ and assume $I = \mathbb{N}$ henceforth. We will also assume $S$ is finite.

#+begin_lemma
$\{X_n\}_n$ is a Markov chain iff for all $n\in\mathbb{N}$ and given arbitrary $s_0, \ldots, s_{n + 1} \in S$, then it holds:

\[
P(X_{n + 1} = s_{n + 1} | X_n = s_n, \ldots, X_0 = s_0) = P(X_{n + 1} = s_{n + 1} | X_n = s_n)
\]
#+end_lemma

#+begin_proof

From left to right. By Markov chain definition, if $\{X_k\}_{k \in I}$ is independent of the past process $\{X_k\}_{m \in I}$ conditionally on $X_n$, then:

\begin{align*}
&P(X_{n + 1} = s_{n + 1}, X_{n - 1} = s_{n - 1}, \ldots, X_0 = s_0 | X_n = s_n) = \\
&P(X_{n + 1} = s_{n + 1} | X_n = s_n) \cdot P(X_{n - 1} = s_{n - 1}, \ldots, X_0 = s_0 | X_n = s_n)
\end{align*}

If we prove that 

\[
\frac{P(X_{n + 1} = s_{n + 1}, X_{n - 1} = s_{n - 1}, \ldots, X_0 = s_0 | X_n = s_n)}{P(X_{n - 1} = s_{n - 1}, \ldots, X_0 = s_0 | X_n = s_n)} = P(X_{n + 1} = s_{n + 1} | X_n = s_n, \ldots, X_0 = s_0)
\]

then we would have arrived at our proof. That derives from:

\begin{align*}
\frac{P(X_{n + 1} = s_{n + 1}, X_{n - 1} = s_{n - 1}, \ldots, X_0 = s_0 | X_n = s_n)}{P(X_{n - 1} = s_{n - 1}, \ldots, X_0 = s_0 | X_n = s_n)} &=
\frac{P(X_{n + 1} = s_{n + 1}, X_n = s_n, \ldots, X_0 = s_0)}{P(X_n = s_n, X_{n - 1} = s_{n - 1}, \ldots, X_0 = s_0)} = \\
&= P(X_{n + 1}=s_{n + 1} | X_{n} = s_{n}, \ldots, X_0 = s_0)
\end{align*}

From right to left. We want to prove that:

\begin{align*}
&P(X_{n + m} = s_{n + m}, \ldots X_{n + 1} = s_{n + 1} | X_n = s_n, \ldots, X_0 = s_0) =\\
&P(X_{n + m} = s_{n + m}, \ldots, X_{n + 1} = s_{n + 1} | X_n = s_n)
\end{align*}

On the one hand, if the right part holds, it easy to prove that:

\begin{align*}
& P(X_0 = s_0, \ldots X_n = s_n ) =\\
& P(X_0 = s_0) \cdot P(X_1 = s_1 | X_0 = s_0) \cdot P(X_2 = s_2 | X_1 = s_1) \cdots P(X_n = s_n | X_{n - 1} = s_{n - 1})
\end{align*}

substituting each:

\[
P(X_i = s_i | X_{i - 1} = s_{i - 1}) = P(X_i = s_i | X_{i - 1} = s_{i - 1}, \ldots, X_0 = s_0) = \frac{P(X_i = s_i, \ldots, X_0 = s_0)}{P(X_{i - 1} = s_{i - 1}, \ldots, X_0 = s_0)}
\]


Summing over all $s_0, \ldots s_{k - 1}$, we get:

\[
P(X_{k} = s_{k}, \ldots, X_n = s_n) = P(X_k = s_k) \cdot P(X_{k + 1} = s_{k + 1} | X_k = s_k) \cdots P(X_n = s_n | X_{n - 1} = s_{n - 1})
\]

Therefore,

\begin{align*}
& P(X_{n + m} = s_{n + m}, \ldots, X_{n + 1} = s_{n + 1} | X_n = s_n, \ldots, X_0 = s_0) =\\
&= \frac{P(X_{n + m}, \ldots, X_0)}{P(X_{n + m - 1}, \ldots, X_0)} \cdot \frac{P(X_{n + m - 1}, \ldots, X_0)}{P(X_{n + m - 2}, \ldots, X_0)} \cdots \frac{P(X_{n + 1}, \ldots, X_0)}{P(X_{n}, \ldots, X_0)} = \\
&= P(X_{n + m} | X_{n + m - 1}) \cdots P(X_{n + 1} | X_{n}) = \frac{P(X_{n + m} = s_{n + m}, \ldots X_{n + 1} = s_{n + 1})}{P(X_n = s_n)} =\\
&= P(X_{n + m} = s_{n + m}, \ldots, X_{n + 1} = s_{n + 1} | X_n = s_n) 
\end{align*}
#+end_proof

** Chapman-Kolmogorov equation
As stated before, in the right to left implication (that now we can assume as characterization of Markov chains), we have shown that transition probabilities can be expressed as:

\begin{align}
& P(X_0 = s_0, \ldots X_n = s_n) = \nonumber \\
& P(X_0 = s_0) \cdot P(X_1 = s_1 | X_0 = s_0) \cdot P(X_2 = s_2 | X_1 = s_1) \cdots P(X_n = s_n | X_{n - 1} = s_{n - 1})
\label{eq:trans-probs}
\end{align}

and also:

\begin{align}
& P(X_{m} = s_{m}, \ldots, X_n = s_n | X_{m - 1} = s_{m - 1})) = \nonumber \\
& = P(X_{m} = s_{m} | X_m = s_m) \cdots P(X_n = s_n | X_{n - 1} = s_{n - 1})
\label{eq:trans-cond-probs}
\end{align}

#+begin_definition
Given $\{X_n\}_{n\in I}$ a Markov chain with finite state space $S$, let us define the initial distribution as $\mu(s) = P(X_0 = s), s \in S$.
#+end_definition

#+begin_definition
Given $\{X_n\}_{n\in I}$ a Markov chain with finite state space $S$, let us define the transition probabilities as 

\begin{align*}
& p_{s, t}(m, n) = P(X_n = t | X_m = s),\quad s,t \in S, \quad n,m \in \mathbb{N}, n\neq m \\ 
& p_{s, t}(n, n) = \mathbb{1}_{s = t}
\end{align*}
#+end_definition

Therefore, we can rewrite Equation \eqref{eq:trans-probs} as:

\[
P(X_k = s_k, k \le n) = \mu(s_0) \cdot p_{s_0, s_1}(0, 1) \cdot p_{s_1, s_2}(1, 2) \cdots p_{s_{n - 1}, s_n}(n - 1, n)
\]

Summing over $m - 1, \ldots, n -1$ in Equation \eqref{eq:trans-cond-probs}, we deduce:

\begin{equation}
p_{s, t}(m, n) = \sum_{s^{(1)} \in S} \ldots \sum_{s^{(n - m - 1)} \in S} p_{s, s^{(1)}}(m, m + 1) \cdots p_{s^{(n - m - 1)}, t}(n - 1, n)
\label{eq:sum-probs}
\end{equation}

#+begin_definition 
We will define the matrix $P(m, n) = (p_{s, t}(m, n))_{s, t \in S}$ henceforth.
#+end_definition

#+begin_proposition
$P$ verifies the semigroup property, best known as Chapman-Kolmogorov equation:

\[
P(m, n) = P(m, l) \cdot P(l, n), \quad \forall m \le l \le n 
\]
#+end_proposition
#+begin_proof
Straightforward from Equation \eqref{eq:sum-probs} 
#+end_proof

** Time-homogeneous Markov chains
#+begin_definition
Given a Markov chain $\{X_n\}$ with finite space state $S=\{0, \ldots, k\}$, it is said to be a time-homogeneous Markov chain iff it holds:

\[
\forall s, t\in S, \forall n \in \mathbb{N} \qquad p_{s, t} (n, n + 1) = p_{s, t} \in [0, 1]
\]

(i.e. the transition probabilities do not depend on the time).

$p_{s, t}$ is called one-step transition probability and $P = (p_{s, t})_{s, t \in S}$ the transition matrix.
#+end_definition

#+begin_proposition
It holds $P(m, n) = P^{n - m}$
#+end_proposition

#+begin_proof
Trivial
#+end_proof


#+begin_proposition
Naming $\mu_n = \left(\mu_n(0), \ldots, \mu_n(k)\right)$, it holds:

\[
\mu_n = \mu_0 \cdot P^n
\]
#+end_proposition

#+begin_proof
Trivial from Equation \eqref{eq:trans-probs}
#+end_proof

#+begin_definition
We define the law of a Markov chain $\{X_n\}$, where $X_n: \Omega \longrightarrow \mathbb{S}$, as the probability distribution of $X: \Omega \longrightarrow S^{\mathbb{N}}$, where $X(\omega) = \{X_n(w)\}_{n \in \mathbb{N}}$.
#+end_definition

#+begin_definition
We will denote:

\[
P_s(A) = P(A | X_0 = s)
\]

for any given state $s\in S$. Let's note that $P_s$ is univocally defined by $P_s(X_k = t) \quad \forall k \ge 0, t \in S$.

We will also denote

\[
\mathbb{E}_s Y = \mathbb{E}(Y | X_0 = s) = \sum_y y P(Y = y | X_0 = s) = \sum_y y P_i(Y = y)
\]
#+end_definition

** Stationarity
#+begin_definition
We say that $\{X_n\}$ is stationary iff $\{X_n\}_{n \ge 0}$ has the same law as $\{X_n\}_{n \ge m}$.
#+end_definition

#+begin_proposition
A Markov chain $\{X_n\}$ is stationary iff it is time homogeneous and all the $X_k$ have the same 
distribution.
#+end_proposition

#+begin_proof
From right to left, if $\{X_n\}$ is stationary, $P(X_0 = s) = P(X_m = s)$ for all $s\in S, m\in \mathbb{N}$
#+end_proof

We will assume all the Markov chains as time-homogeneous ones henceforth, unless stated 
otherwise.
** Stopping times and strong Markov property
#+begin_definition
Given $\{X_n\}$ a Markov chain, defined over $(\Omega, \mathcal{F}, P)$, then a stopping time is a random variable 
$\tau : \Omega \mapsto \mathbb{N} \bigcap \{\infty\}$ such that:

\[
\{\tau = n \} \in \mathcal{F}_n = \sigma(X_0, X_1, \ldots, X_n), \quad \forall n \in \mathbb{N}
\]

Moreover, we call the $\sigma$ -algebra of events previous to $\tau$, namely $\mathcal{F}_{\tau}$, the one which contains all
the events $A \in \mathcal{F}$ following:

\[
A\bigcap \{\tau = n \} \in \mathcal{F}_n
\]
#+end_definition

For example, in the case of a coin, the first instant (or coin toss) $\tau$ where we get 4 heads 
in a row, is a valid stopping time, because we only have to account for the previous random 
variables; whereas the first toss where we are just one toss away from having obtained 4 heads 
is not a valid stopping time, since it involves future events.

Given $S = \{i_1, i_2, \ldots\}$ we would denote $S^m = \{(i^{(1)}, \ldots, i^{(m)}): i^{(j)} \in S\}$.

#+begin_proposition
Let $\{X_n\}$ be a Markov chain with $S$ as state space and stationary transition probabilities.
Let $\tau$ be a stopping time. Then for all $m\in \mathbb{N}, C \subseteq S^m, A \in \mathcal{F}_\tau,
i \in S$, if $P(A \bigcap \{X_\tau = i\}) > 0$, then it holds:

\begin{equation}
P\left((X_{\tau + 1}, \ldots, X_{\tau + m}) \in C | A, X_{\tau} = i\right) = 
P\left((X_{\tau + 1}, \ldots, X_{\tau + m}) \in C | X_{\tau} = i\right)
\label{ec:strong-mc}
\end{equation}
#+end_proposition

#+begin_proof
Let us start taking $m = 1, C = \{j\}$. Then, intersecting over $\{\tau = n\}$, we have:

\begin{align*}
P\left(X_{\tau + 1} = j, A, X_{\tau} = i\right) &=
\sum_{n = 0}^{\infty} P\left(\tau = n, X_{n + 1}, A, X_n = i\right) = \\
&= \sum_{n = 0}^{\infty} P\left(\tau = n, A, X_n = i\right) \cdot P\left(X_{n + 1} = j | \tau = n, A, X_n = i\right) = \\
&= \sum_{n = 0}^{\infty} P\left(\tau = n, A, X_n = i\right) \cdot P\left(X_{n + 1} = j | X_n = i\right) = \\
&= p_{i,j} \sum_{n = 0}^{\infty} P\left(\tau = n, A, X_n = i\right) = p_{i, j} P\left(A, X_{\tau} = i\right)
\end{align*}

where we have used $A\bigcap \{\tau = n\} \in \mathcal{F}_n$ to simplify 
$P\left(X_{n + 1} = j | \tau = n, A, X_n = i\right)$
as $P\left(X_{n + 1} = j | X_n = i\right)$. Therefore, using the proven equality we can show:

\[
P\left(X_{\tau + 1} = j | A, X_\tau = i\right) = \frac{P\left(X_{\tau + 1} = j, A, X_{\tau} = i\right)}{P(A, X_{\tau} = i)} = p_{i, j}
\]

Applying several times this argument, we have:

\begin{align*}
& P\left(X_{\tau + 1} = i_1, X_{\tau + 2} = i_2, \ldots, X_{\tau + m} = i_m | A, X_{\tau} = i\right) =\\
&= P\left(X_{\tau + 1} = i_1 | A, X_{\tau} = i\right) \cdot P\left(X_{\tau + 2} = i_2 | A, X_{\tau} = i, X_{\tau + 1} = i_1\right) \cdots \\
&\cdots P\left(X_{\tau + m} = i_m | A, X_{\tau} = i, X_{\tau + 1} = i_1, \ldots X_{\tau + m - 1} = i_{m - 1}\right) = p_{i, i_1} p_{i_1, i_2} \cdots p_{i_{m - 1}, i_m}
\end{align*}

In particular, when $A$ is the whole space $\Omega$, we arrive at:

\[
P\left(X_{\tau + 1} = i_1, X_{\tau + 2} = i_2, \ldots, X_{\tau + m} = i_m | X_{\tau} = i\right) = p_{i, i_1} p_{i_1, i_2} \cdots p_{i_{m - 1}, i_m}
\]

which shows the equality:

\[
P\left(X_{\tau + 1} = i_1, \ldots, X_{\tau + m} = i_m | A, X_{\tau} = i\right) =
P\left(X_{\tau + 1} = i_1, \ldots, X_{\tau + m} = i_m | X_{\tau} = i\right) 
\]

We have shown that Equation \eqref{ec:strong-mc} holds for $C = \{(i_1, \ldots, i_m)\}$. For
$C \subseteq S^m$ it would suffice summing over $(i_1, \ldots, i_m) \in C$.
#+end_proof

The previous result says us that all the Markov chains (in discrete time) have the strong Markov 
property, and it can be interpreted as the Markov chain restarting each time it hits the state 
$i \in S$.

** Hitting times
The probabilities $p_{i, j}^{(n)} = P_i\left(X_n = j\right)$ gives us of the probability of the
chain reaching state $j$ in the $n$ -th period, if it starts from $i$. But the state $j$ could have
been visited before. We are interested now in finding the first time that a given state is reached.

#+begin_definition
We define the hitting time for the state $j \in S$ as:

\[
\tau_j = min \{n > 0 : X_n = j \}
\] 
#+end_definition

#+begin_definition

We call first hitting time probability of the state $j$, provided that the chain starts in the 
state $i$, to:

\[
f_{i,j}^{(n)} = P_i\left(\tau_j = n\right) = P_i\left(X_n = j, X_m \neq j \quad \forall m = 1, \ldots, n - 1 \right)
\]

and we will define the total probability of reaching $j$ as $f_{i, j} := \sum_{n = 0}^{\infty} f_{i,j}^{(n)} = P_i\left(\tau_j < \infty\right)$

Note that $f_{i,j} = \probi{X_n = j \textrm{ for some } n\ge 1}$
#+end_definition

Note that we coul have $f_{i, j} < 1$ iff $P_i\left(X_n \neq j, \forall n \ge 1\right) > 0$.

#+begin_definition
We will call return time distribution for the state $i$ to $f_{i,i}^{(n)} = P_i \left(\tau_i = n\right)$, 
and we will denote $f_{i,i} = P_i\left(\tau_i < \infty\right)$ (i.e. the probability of ever returning 
to the start state $i$.
#+end_definition

$f_{i, j}$ can be computed using the recurrence:

\begin{equation}
f_{i,j} = \probi{X_1 = j} + \sum_{k \neq j} \probi {X_1 = k} \probi {\tau_j < \infty | X_1 = k } = p_{i,j} + \sum_{k\neq j} p_{i,k} f_{k,j}
\label{eq:fij-recurrence}
\end{equation}

solving first the system formed by the equations given by $i\neq j$ (if we have $n$ states, that would be $n \cdot (n - 1)$ equations), and then substituting the computed $f_{k,j}$ values to get $f_{j,j}$.

#+begin_lemma
If $f_{i,j} = 1$ and $p_{i,k} > 0$, then $f_{k,j} = 1$
#+end_lemma

#+begin_proof
Straightforward from Equation \eqref{eq:fij-recurrence} and the fact that $\sum_{k \in S} p_{i,k} = 1$
#+end_proof

*** Computation through absorption
Let us consider a fixed state $j$. The aim is to compute $f_{i,j}^{(n)}$ with $i\neq j$. 
We could freeze the chain $\{X_n\}$ once it hits $j$ in that state, that is, taking:

\[
\tildemc = \twopartdef 
             {X_n} { X_r \neq j \; \forall r < n } 
             {j} {X_r = j \textrm{ for some } r  < n}
\]

That is, $j$ has been transformed into an absorbing state, such that $\tildemc$ cannot leave.

The transition matrix for $\tildemc$ is given by:

\[
\tildeprob_{i, k} = \probi{\tildex_1 = k} = 
  \threepartdef 
    { p_{i,k} } { i\neq j }
    { 0 }       { i = j, k \neq j }
    { 1 }       { i = j, k = j }
\]

That is, the transition matrix $\tildeP$ has the same rows as $P$, except for the $j$ -th row, 
which has been substituted by $(0, \ldots, 0, \underset{j}{1}, 0, \ldots, 0)$. Therefore 
we have that the $i, j$ entry for the matrix $\tildeP^n$ is:

\[
\tildep_{i,j}^{(n)} = \probi{\tildemc = j} = \probi{\tau_j \le n}
\]

and hence:

\[
f_{i,j}^{(n)} = \probi{\tau_j \le n} - \probi{\tau_j \le n - 1} = \tildep_{i, j}^{(n)} - \tildep_{i, j}^{(n - 1)}
\]

So obtaining $f_{i,j}^{(n)}$ can be done by computing $\tildeP^{n - 1}$ and $\tildeP^n$, 
except for $j = i$. To compute that last probability, we could use:

\[
f_{jj}^{(n)} = \twopartdef
  { p_{jj} } { n = 1 }
  { \sum_{k \in S, k \neq j} p_{j,k} f_{k,j}^{(n - 1)} } { n \ge 2 }
\]

\begin{example}
We consider a Markov chain with states $S = \{1,2,3\}$ and the following transition matrix:

\[
  P = \left(
  \begin{array}{ccc}
  \frac{1}{3} & \frac{2}{3} &      0      \\
  \frac{1}{4} & \frac{1}{2} & \frac{1}{4} \\
      0       & \frac{3}{4} & \frac{1}{4}
  \end{array}
  \right)
\]

To compute the time it takes us to reach the state $3$, we should consider:

\[
\tildeP = \left(
  \begin{array}{ccc}
  \frac{1}{3} & \frac{2}{3} & 0 \\
  \frac{1}{4} & \frac{1}{2} & \frac{1}{4} \\
       0      &      0      &   1
  \end{array}
\right) = \frac{1}{10} 
\threemat {1 & 2 & 4} {1 & -1 & 3} {1 & 0 & 0} \cdot
\threemat {1 &   &  } {  &  0 &  } {  &   & \frac{5}{6}} \cdot
\threemat {0 & 0 & 10}{3 & -4 & 1} {1 & 2 &-3}
\]

It is easy to show, calling $\alpha = \frac{5}{6}$:

\[
\tilde{P}^n = \threemat
            { \frac{2}{5} \alpha^n & \frac{4}{5} \alpha^n & 1 - \alpha^{n - 1}}
            { \frac{3}{10}\alpha^n & \frac{3}{5} \alpha^n & 1 - \frac{3}{4}\alpha^{n - 1} }
            { 0 & 0 & 1 }
\]

Therefore:

\[
P_1 \left(\tau_3 = n\right) = \tildep_{1,3}^{(n)} - \tildep_{1,3}^{(n-1)} =
1 - \alpha^{n - 1} -  (1 - \alpha^{n - 2}) = (1 - \alpha) \alpha^{n - 2} = \frac{1}{6}\alpha^{n - 2} n \ge 2
\]

\[
P_2 \left( \tau_3 = n \right) = \twopartdef { \frac{1}{4} } { n = 1 }
                                            { \tildep_{2,3}^{(n)} - \tildep_{2,3}^{(n-1)} = \frac{1}{8} \alpha^{n - 2} } { n\ge 2 }
\]

To go from $3$ to itself, we could go directly or passing by $2$ (we could not go through
$1$ since $p_{3,1} = 0$:

\[
P_3\left(\tau_3 = n\right) = \threepartdef
  { \frac{1}{4} } { n = 1 } 
  { \frac{3}{16} } { n = 2 }
  { \frac{3}{32} \alpha^{n - 3} } { n \ge 3 }
\]
\end{example}

*** Computation through transition probabilities

We could ask ourselves whether it is possible to relate $f_{i,j}^{(n)}$ to $p_{i,j}^{(n)}$
directly. It holds:

\begin{align}
p_{i,j}^{(n)} &= \probi{X_n = j} = \sum_{m = 1}^{n} \probi{\tau_j = m} 
\probi{X_n = j | \tau_j = = m} = \nonumber \\
&= \sum_{m = 1}^{n} \probi{\tau_j = m} \probj{X_{n-m} = j} = 
\sum_{m = 1}^n f_{i, j}^{(m)} p_{j,j}^{(n - m)}
\label{eq:ps-fs-relation}
\end{align}   

It is not possible to express $f_{i,j}^{(n)}$ in terms of $p_{i,j}^{(n)}$, but taking the following generating functions, we can determine a theoretical relationship between both:

\[
P_{i,j}(s) = \sum_{n = 1}^{\infty} p_{i,j}^{(n)} s^n \qquad 
F_{i,j}(s) = \sum_{n = 1}^{\infty} f_{i,j}^{(n)} s^n
\]

According to $\eqref{eq:ps-fs-relation}$:

\[
P_{i,j}(s) = \sum_{n = 1}^{\infty} \sum_{m = 1}^n f_{i, j}^{(m)} p_{j,j}^{(n - m)} s^n = 
\sum_{n = 1}^{\infty} \sum_{m = 1}^{n - 1} f_{i, j}^{(m)} p_{j,j}^{(n - m)} s^n + 
\sum_{n = 1}^{\infty} f_{i, j}^{(n)} \underbrace{p_{j,j}^{(0)}}_{1} s^n \underset{(\ast)} = F_{i,j}(s) P_{j,j}(s) + F_{i,j}(s)
\]

where in $(\ast)$ it has been used that $\sum_{n = 1}^{\infty} \sum_{m = 1}^{\infty} p_{i, j}^{(n)} f_{i,j}^{(m)} s^{n + m}$ can be rewritten as (fixes $k$, there we can take finite $m$ positive values and $k - m$ positive):

\[
\sum_{n = 1}^{\infty} \sum_{m = 1}^{n - 1} f_{i, j}^{(m)} p_{j,j}^{(n - m)} s^n
\]

We deduce:

\begin{equation}
F_{i,j}(s) = \frac{P_{i,j}(s)}{1 + P_{j,j}(s)}
\label{eq:Fs-Ps-relation}
\end{equation}

Although this is just a theoretical relationship for the moment, we can observe, on the one hand:

\[
F_{i,j}(1) = f_{i,j} = \probi{\tau_j < \infty}
\]
and if the condition $f_{i,j} = 1$ is met:

\[
F_{i,j}'(j) = \sum_{n = 1}^{\infty} n f_{i,j}^{(n)} = \expecti{\tau_j}
\]

#+begin_definition
Taking a fixed state $j$, we can define:

1. The expected number of visited to $j$  as $P_{i,j}(1) = \sum_{n = 1}^{\infty} p_{i,j}^{(n)}$
2. The total number of visits to $j$  as $V_j = \sum_{n = 1}^{\infty} \mathbb{1}_{X_n = j}$
#+end_definition

#+begin_proposition
It holds that $\expecti{V_j} = P_{i,j}(1)$
#+end_proposition

#+begin_proof
Straightforward from $\expecti{V_j} = \sum_{n = 1}^{\infty} \expecti{\mathbb{1}_{X_n = j}} = \sum_{n = 1}^{\infty} p_{i,j}^{(n)}$
#+end_proof

*** Average arrival times

#+begin_definition
If $f_{i,j} = 1$, we define the average arrival time from $i$ to $j$ as:

\[
e_{i,j} = \expecti{\tau_j} = \sum_{n = 1}^{\infty} n f_{i,j}^{(n)}
\]
#+end_definition

#+begin_proposition
e_{i,j} = 1 + \sum_{k \neq j} p_{i, k} e_{k, j}
#+end_proposition

#+begin_proof
It holds: $f_{i,j}^{(1)} = p_{i,j}$ and $f_{i,j}^{(n)} = \sum_{k\neq j} p_{i,k} f_{k,j}^{(n-1)}$.

Therefore, and having in mind that $f_{i,j} = 1$.

\begin{align*}
e_{i,j} &= \sum_{n = 1}^{\infty} n f_{i,j}^{(n)} = p_{i,j} + \sum_{n = 2}^{\infty} n \sum_{k \neq j} p_{i,k} f_{k,j}^{(n-1)} \\
        &= p_{i,j} + \sum_{k \neq j} p_{i,k} \sum_{n = 2}^{\infty} n f_{k,j}^{(n-1)} \\
        &= p_{i,j} + \sum_{k \neq j} p_{i,k} \bigg\{ \sum_{n = 2}^{\infty} f_{k,j}^{(n-1)} + \sum_{n = 2}^{\infty} (n-1)f_{k,j}^{(n-1)} \bigg\} \\
        &= p_{i,j} + \sum_{k \neq j} p_{i,k} f_{k,j} + \sum_{k \neq j} p_{i,k} e_{k,j} \\
        &\underset{\eqref{eq:fij-recurrence}}{=} 1 + \sum_{k\neq j} p_{i,k} e_{k,j}
\end{align*}
#+end_proof

Note this last proposition can be used to compute $e_{i,j}$ with a computer.

*** Number of visits to an state

#+begin_proposition
If $f_{j,j} \neq 1$, we have:

\[
  \expecti{V_j} = \frac{f_{i,j}}{1 - f_{j,j}}
\]

Moreover, it holds $f_{i,i} = 1 \dimplies \expecti{V_i} = \infty$.

Let us note this is a characterization of $f_{i,i} = 1$. Since $\expecti{V_i} = 
\sum_{n > 0} p_{i,i}^{(n)}$, it holds:

\[
  \probi{X_n = i \textrm{ for some } n} = 1 \dimplies
  \probi{X_n = i \textrm{ for infinitely many } n} = 1
\]

\label{prop:fii-equiv}
#+end_proposition

#+begin_proof
From \eqref{eq:Fs-Ps-relation} we can deduce:

\[
P_{i,j}(1) = F_{i,j}(1) \bigg\{1 + P_{j,j}(1) \equiv \expecti{V_j}\bigg\} = \frac{f_{j,j}}{1 - f_{j,j}}
\]

If $f_{i,j} \neq 1$ then $\probi{\tau_j = \infty} > 0$ and hence $\expecti{\tau_j} = \infty$.
#+end_proof

#+begin_lemma
There is an equivalence between:

1. $\exists n >0 : p_{i,j}^{(n)} > 0$
2. $\expecti{V_j} > 0$
3. $f_{i,j} > 0$

\label{lemma:fij-equivs}
#+end_lemma

#+begin_proof
Since $\expecti{V_j} = \sum_{n = 1}^{\infty} p_{i,j}^{(n)}$, clearly i. is equivalent to ii.

ii. is equivalent to iii. can be deduced from $\expecti{V_j} = f_{i,j}(1 + \expectj{V_j})$.
#+end_proof

** Classification of states
*** Communicating classes

#+begin_definition
The state $i\in E$ communicates with $j\in S$, and we will write it like $i \rightarrow j$
iff $p_{i,j}^{(n)} > 0$ for some $n > 0$.

If $i \longrightarrow j$ and $j \longrightarrow i$ then we will say that both states communicate and
we will represent it as $i \dgoto j$.
#+end_definition

#+begin_proposition
Given $i \neq j$, it holds:

\[
i \goto j \dimplies \expecti{V_j} > 0 \dimplies f_{i,j} > 0
\]
\label{goto-characterization}
#+end_proposition

#+begin_proof
Straightforward from Lemma \eqref{lemma:fij-equivs}.
#+end_proof

#+begin_definition
State $i\in S$ is essential if $i \goto j$ always implies $j \goto i$. We denote the set 
of essential states by $S^{\ast}$.
#+end_definiton

#+begin_lemma
If $i\in S^{\ast}$ and $i \goto j$, then $j \in S^{\ast}$
#+end_lemma

#+begin_proof
Given $j \goto k$, then by transivity $i \goto k$. Since $i$ is essential, $k \goto i$, 
which applying transitivity again from $i \goto j$, gives us $k \goto j$.
#+end_proof

#+begin_proposition
$\dgoto$ is an equivalence relationship in $S^{\ast}$, and we can decompose:

\[
S^{\ast} = C_1 \cup C_2 \cup \ldots \cup C_r
\]

where for every $i, j \in C_k$, it holds $i \dgoto j$, and if $i \in C_k, j \in C_l$ where $k \neq l$, then $i \not\goto j$ or $j \not\goto i$.

\label{prop:equiv-classes}
#+end_proposition

#+begin_proof
1. Reflexivity holds because given $i \in S^{\ast}$, then $p_{i,j} > 0$ for some $j \in S$. Because of the previous lemma $j \in S^{\ast}$. Therefore $i \goto j$ implies $j \goto i$ because of the essentiality.
2. Transitivity holds trivially.
3. Transitivity holds because if $p_{i,j}^{(n)} > 0$ and $p_{j,k}^{(m)} > 0$ then
\[
p_{i,k}^{(n + m)} \ge p_{i,j}^{(n)} \cdot p_{j,k}^{(m)} > 0
\]

The second part is trivial from the deduced equivalence property.
#+end_proof

Therefore, reordering the states of the matrix, with $P_k$ is the transition matrix for the
states in $C_k$ (which only communicate with themselves), where the last rows are formed by the 
transition probabilities from the non-essential states: $Q_k$,
where those are the probabilities of going from $S - S^{\ast}$ to $C_k$ (and never returning), 
and $W$ where that is the probability of the non-essential states of communicating with
themselves.

\begin{equation}
  \left(\begin{array}{cccccccccc}
  \gcell P_1    &        &            &       &        &       &            &        & \\
                & \rcell & \rcell     & \rcell&        &       &            &        & \\
                & \rcell & \rcell P_2 & \rcell&        &       &            &        & \\
                & \rcell & \rcell     & \rcell&        &       &            &        & \\
                &        &            &       & \ddots &       &            &        & \\
                &        &            &       &        &\bcell &   \bcell   & \bcell & \\
                &        &            &       &        &\bcell & \bcell P_r & \bcell & \\
                &        &            &       &        &\bcell &   \bcell   & \bcell & \\
    \rowcolor{gray!20}
      Q_1       &        &   Q_2      &       & \ldots &       &    Q_r     &        & W\\
  \end{array}\right)
\label{eq:irreducible-classes-matrix}
\end{equation}

Each $C_k$ is said to be an irreducible and closed sub-chain of the original transition matrix 
$P$; closed because from one state from $C_k$ we can only go back to another state in the same
set; irreducible because all their states communicate among themselves. The same structure of
power matrices appears in $P^n$, $n > 2$:

\begin{equation}
  \left(\begin{array}{cccccccccc}
  \gcell P_1^{n}   &        &                  &       &        &       &                   &        & \\
                   & \rcell & \rcell           & \rcell&        &       &                   &        & \\
                   & \rcell & \rcell P_2^{n}   & \rcell&        &       &                   &        & \\
                   & \rcell & \rcell           & \rcell&        &       &                   &        & \\
                   &        &                  &       & \ddots &       &                   &        & \\
                   &        &                  &       &        &\bcell &   \bcell          & \bcell & \\
                   &        &                  &       &        &\bcell & \bcell P_r^{n}    & \bcell & \\
                   &        &                  &       &        &\bcell &   \bcell          & \bcell & \\
    \rowcolor{gray!20}
      Q_1 \cdot P_1^{n-1} & & Q_2 \cdot P_2^{n-1} &    & \ldots &       & Q_r \cdot P_r^{n} &        & W^n\\
  \end{array}\right)
\label{eq:irreducible-classes-pow-matrix}
\end{equation}

#+begin_definition
A Markov chain where all its states are essential and with only a communicating class is called 
irreducible Markov chain.
#+end_definition
*** Recurrence and transience

#+begin_definition
An state $i\in S$ is called recurrent iff $f_{i,i} = 1$ and transient iff $f_{i,i} < 0$
#+end_definition

By Proposition \eqref{prop:fii-equiv} it is easy to show the following characterization:

#+begin_proposition
It holds:

1. $i\in S$ is recurrent iff $\probi{X_n = i \textrm{ for infinitely many } n} = 1$
2. $i\in S$ is transient iff $\probi{X_n = i \textrm{ for infinitely many } n} = 0$
\label{prop:rec-tran-characterization}
#+end_proposition

If an state is recurrent, then $\probi{V_i = \infty} = 1$ and $\expecti{V_i} = \infty$ and 
$\probj{V_i = 0 \vee V_i = \infty} = 1$. If an state is transient, then $\probi{V_i < \infty}$ 
and $\expecti{V_i} < \infty$.

Therefore $\sum_{n = 1}^{\infty} p_{i,i}^{(n)}$ diverges when $i$ is recurrent and converges
when $i$ is transient.

#+begin_proposition
If $i$ is a recurrent state and $j$ communicates with $i$, then $f_{j,i} = f_{i,j} = f_{j,j} = 1$, 
and $j$ is recurrent. Therefore, all non essential states are transient.
\label{prop:recurrent-classes}
#+end_proposition

#+begin_proof
By Proposition \eqref{goto-characterization}, $f_{i,j} > 0$. Since $i$ is recurrent $f_{ii} = 0$
and by Equation \eqref{eq:fij-recurrence}:

\[
1 = f_{i,i} = p_{i,i} + \sum_{k \neq i} p_{i,k} f_{k,i}
\]

$i \goto j$ means there exists $k_1, k_2, \ldots k_r$ verifying:

\[
p{i, k_1} \cdot p_{k_1, k_2} \cdots p_{k_{r}, k_j} > 0
\]

Since $\sum_{k} p_{k,k} = 1$, and $0 \le f_{k,i} \le 1$, then it must hold $f_{k,i} = 1$ for all
$k$ such that $p_{i,k} > 0$. In particular $f_{k_1,i} = 1$, and we deduce:

\[
1 = f_{k_1,i} = p_{k_1,k_1} + \sum_{k\neq k_1} p_{k_1,k} f_{k,i}
\]

We get $1 = f_{k_2, i}$ by an analogous argument, and we can recursively proceed until we 
arrive at $f_{j,i} = 1$.

Since we have proven $f_{i,i} > 0$, $f_{i,j} > 0$, $f_{j,i} = 1$ then by Lemma \eqref{lemma:fij-equivs}
we deduce there exist $u, v, n$: $p_{i,j}^{(u)} > 0$, $p_{j,i}^{(v)}, $p_{i,i}^{(n)} > 0$.
#+end_proof

So for every $n \ge u + v$ we deduce:

\[
p_{j,j}^{(n)} \ge p_{j,i}^{(v)} p_{i,i}^{(n - u - v)} p_{i,j}^{(u)}
\]

Since $f_{i,i} = 1$, then $\sum_{n = 1}^{\infty} p_{i,i}^{(n)} = \infty$ by Proposition \eqref{prop:fii-equiv}, 
and therefore $\sum_{n = u + v}^{\infty} p_{i,i}^{(n)} = \infty$

\begin{align*}
\sum_{n = 1}^{\infty} p_{j,j}^{(n)} \ge \sum_{n = u + v}^{\infty} p_{j,j}^{(n)} \ge
p_{j,i}^{(v)} p_{i,j}^{(u)} \sum_{n = u + v}^{\infty} p_{i,i}^{(n)} = \infty
\end{align*}

Again from Proposition \eqref{prop:fii-equiv} we deduce $f_{j,j} = 1$. We have proved $j$ is
recurrent, but also that $j \goto i$, and we can deduce $f_{i,j} = 1$ by the same procedure
we started this demonstration with.
#+end_proof

#+begin_corollary
If $i,j \in S$ are in the same communicating class they are both either recurrent or transient.
\label{corollary:comm-classes}
#+end_corollary

#+begin_definition
We will say a communicating class is recurrent (resp. transient) iff one of its states (iff
all, by the previous corollary) are recurrent (resp. transient).
#+end_definition

#+begin_proposition
All the closed irreducible subchains of a Markov chain (with finite space state S) are recurrent, 
and every Markov chain has at least one subchain of such type. A state is transient iff it is 
non-essential.
\label{prop:one-recurrent-class}
#+end_proposition

#+begin_proof
Let us fix some $i \in S$. We have 

\[
\sum_{j \in S} \expecti{V_j} = \sum_{j \in S} \sum_{n = 1}^{\infty} p_{i,j}^{(n)} = 
\sum_{n = 1}^{\infty} \sum_{j \in S} p_{i,j}^{(n)} = \sum_{n = 1}^{\infty} 1 = \infty
\]

And therefore, it exits at least one $\expecti{V_j} = \infty \equiv f_{j,j} = 1$, so the subchain which
contains $j$ is recurrent. The same argument can be applied to the other subchains. Therefore, if we have
a chain and a certain state $j$ in that chain, $f_{j,j} = 1$ and $j$ cannot be transient. In other words,
if $j$ is transient, $j$ is non-essential. 
#+end_proof

#+begin_corollary
In a Markov chain with finitely many states, a communicating class is recurrent iff it is closed.
#+end_corollary

#+begin_proof
If we have a non closed class $C$, there exist $i \in C, j \in S - C$ such that $p_{i,j} > 0$ and
$p_{j, i} = 0$. Therefore $f_{j,i} = 0$ by \eqref{goto-characterization}.

Therefore: 

\begin{align*}
f_{i,i} &= p_{i,i} + \sum_{k \neq i} p_{i, k} f_{k,i} = \\
        &= p_{i,i} + \sum_{k \neq i, j} p_{i, k} f_{k, i} < \\
        &< \sum_{k \neq j} p_{i, k} \underset{p_{i,j} > 0}{<} 1
\end{align*}

and the class would not be recurrent.

Reciprocally, Proposition \eqref{prop:one-recurrent-class} gives us the result we want.
#+end_proof

We are going to make the classification among the recurrent states even finer.

#+begin_definition
We say that recurrent state $i \in S$ is:
1. positive recurrent iff $e_{i,i} < \infty$.
2. null recurrent iff $e_{i,i} = \infty$.
#+end_definition

#+begin_lemma
A state $i$ is recurrent positive iff:

\[
lim_{s\nearrow 1} \frac{1 - F_{i,i}(s)}{1 - s} < \infty \dimplies lim_{s\nearrow 1} (1 - s) \bigg\{1 + P_{i,i}(s)\bigg\} > 0
\]

\label{lemma:positive-rec-characterization}
#+end_lemma

#+begin_proof
Let us observe that for the limit exists it must be $\lim_{s\nearrow 1} F_{i,i}(s) = f_{i,i} = 1$ iff $i$ is recurrent.

\[
\lim_{s\nearrow 1} \frac{1 - F_{i,i}(s)}{1 - s} = \frac{1}{1 - s} \sum_{n = 1}^{\infty} (1 - s^n) f_{i,i}^{(n)} = 
\sum_{n = 1}^{\infty} (1 + s + \ldots + s^{n-1}) f_{i,i}^{(n)}
\]

which tends to $\sum_{n = 1}^\infty n f_{i,i}^{(n)} = e_{i,i}$.

The second part is deduced from Equation \eqref{eq:Fs-Ps-relation}.

#+begin_proposition
If $i,j$ are communicating recurrent states, then they are both positive recurrent or null recurrent states.
\label{prop:all-positive-all-null}
#+end_proposition

#+begin_proof
By the procedure used in the proof of Proposition \eqref{prop:recurrent-classes}, we have:

\[
p_{j,j}^{(n)} \ge p_{j,i}^{(v)} \cdot p_{i,i}^{(n-u-v)} \cdot p_{i,j}^{(u)} > 0 \forall n > u + v
\]

Therefore:

\begin{align*}
(1-s) \bigg\{1 + P_{j,j}(s)\bigg\} = (1-s) \bigg\{1 + \sum_{n = 1}^{\infty} p_{j,j}^{(n)} s^n\bigg\} = \\
(1-s) \bigg\{1 + \sum_{n = 1}^{u + v} p_{j,j}^{(n)} s^n + \sum_{n = u + v + 1}^{\infty} p_{j,j}^{(n)} s^n \bigg\} \ge \\
(1-s) \bigg\{1 + \sum_{n = 1}^{u + v} p_{j,j}^{(n)} s^n + s^{u + v} p_{i,j}^{(u)} p_{j,i}^{(v)} \sum_{n = 1}^{\infty} p_{i,i}^{(n)} s^n \ge \\
(1-s) \bigg\{1 + s^{u + v} p_{i,j}^{(u)} p_{j,i}^{(v)} P_{i,i}(s) \bigg\} =\\
(1-s) \bigg\{1 + P_{i,i}(s)\bigg\}s^{u + v} p_{i,j}^{(u)} + (1-s) \bigg\{1 - s^{u + v} p_{i,j}^{(u)} p_{j,i}^{(v)} \bigg\}
\end{align*}

Hence:

\[
\lim_{s\nearrow 1} (1-s) \bigg\{1 + P_{j,j}(s)\bigg\} \ge p_{i,j}^{(u)} p_{j,i}^{(v)} \lim_{s\nearrow 1} (1-s) \bigg\{1 + P_{i,i}(s)\bigg\}
\]

And exchanging the roles of $i$ and $j$, we deduce $i$ is positive recurrent iff $j$ is.
#+end_proof

#+begin_proposition
Every irreducible Markov chain with a finite number of states is positive recurrent
#+end_proposition

#+begin_proof
Let us fix a $s \in [0,1[$. We have, using that $\sum_{n = 1}^{\infty} = \frac{s}{1 - s}$:

\[
\sum_{j \in S} (1-s) F_{i,j}(s) \bigg\{1 + P_{j,j}(s)\bigg\} \underset{\textrm{\eqref{eq:Fs-Ps-relation}}}{=} 
(1 - s) \sum_{j \in S} P_{i,j}(s) = (1-s) \sum_{n = 1}^{\infty} s^n \underbrace{\sum_{j\in S} p_{i,j}^{(n)}}_{1} = s
\]

Taking $\lim_{s \nearrow 1}$ we have $\sum_{j \in S} \lim_{s \nearrow  1} (1-s) F_{i,j}(s) = 1$

Therefore, it must exist $j \in S$ with $\lim_{s \nearrow  1} (1-s) F_{i,j}(s) > 0$. By Lemma \eqref{lemma:positive-rec-characterization},
we deduce $j$ is positive recurrent, therefore recurrent. By Proposition \eqref{prop:recurrent-classes} all states
communicating with $j$ are also recurrent, and by Proposition \eqref{prop:all-positive-all-null}, all the states of
the chain are positive recurrent.
#+end_proof

*** Absorption

Although the concept of absorbing state has arisen before, we give a formal definition here:

#+begin_definition
A state $i\in S$ is absorbing iff $p_{i,i} = 1$.
#+end_definition

Let us observe the matrix \eqref{eq:irreducible-classes-matrix}. This matrix poses some interesting questions for
the non-essential states. Let us take a non-essential state, namely $i$. Then it is likely that it will go to a
state in $S^{\ast}$ at some point, and never comes back. 

#+begin_definition
We call the absorbing time to the following random variable:

\[
\tau^{\ast} = \min \{n > 0: X_n \in S^{\ast}\}
\]

If $\tau^{\ast} < \infty$, we can define the entry absorbing state as $X_{\tau^{\ast}}$.

We define:

1. The absorbing probability as $f_{i}^{\ast} = \probi{\tau^{\ast} < \infty}$.
2. Taking $j\in S^{\ast}$, we can define the probability of being absorbed by $j$ as
$f_{i,j}^{\ast} = \probi{\tau^{\ast} < \infty, X_{\tau^{\ast}} = j}$.
3. Since we can decompse $S^{\ast} = C_1 \cup C_2 \cup \ldots \cup C_r$ by the Proposition
\eqref{prop:equiv-classes}. Given $C = C_i$, we can define the probability of the state $i$
being absorbed by the subchain $C$ as:

\[
f_{i,C}^{\ast} = \probi{\tau^{\ast} < \infty, X_{\tau^{\ast}} \in C}
\]
#+end_definition

#+begin_proposition
The following relations hold for each $i \not\in S^{\ast}$:

1. $f_i^{\ast} = \sum_{j \in S^{\ast}} p_{i,j} + \sum_{j \not\in S^{\ast}} p_{i,j} f_{j}^{\ast}$
2. $f_{i,j} = p_{i,j} + \sum_{k \not\in S^{\ast}} p_{i,j} f_{k,j}^{\ast}$
2. $f_{i,C}^{\ast} = \sum_{j \in C} p_{i,j} + \sum_{j \not\in S^{\ast}} p_{i,j} f_{j}^{\ast}$
#+end_proposition

It is obvious that $f_{i,C}^{\ast} = \sum_{j \in C} f_{i,j}^{\ast}$. Once the chain enters the
subchain, $C$, it does so with the initial probabilities 
$(f_{i,j}^{\ast} / f_{i,C}^{\ast})_{j \in C}$.

It we call $V = \bigg(\expecti{V_j}\bigg)_{i,j \not\in S^{\ast}}$, we have, taking a look at
the matrix that \eqref{eq:irreducible-classes-pow-matrix} that $V = \sum_{n = 1}^{\infty} W^n$.

Also, we can define $Q = (Q_1, \ldots, Q_r)$ the matrix of transition probabilities from 
$S - S^{\ast}$ to $S^{\ast}$, and $q = Q \cdot \left(\begin{array}{c} 1 \\ 1 \\ \vdots \\ 1 \end{array}\right)$ (the row-wise sum of $Q$). And we will call 
$F^{\ast} = (f_{i,j}^{\ast})_{i \in S - S^{\ast}, j \in S^{\ast}}$,
$f^{\ast} = (f_{i}^{\ast})_{i \in S - S^{\ast}}$.

With those notations, we can establish the following proposition:

#+begin_proposition
The following relations hold:

\begin{align}
F^{\ast} &= (I + V)Q \label{prop:Fast-matrix}\\
f^{\ast} &= (I + V)q \label{prop:fast-matrix}
\end{align}

The distribution for $\tau^{\ast}$ is $\probi{\tau^{\ast} = n} = B^{n - 1}q, \quad n \in \mathbb{N}$
\label{prop:fast-matrices}
#+end_proposition

#+begin_proof
Let us fix $i\in S - S^{\ast}, j \in S^{\ast}$. We have: 

\begin{align}
\probi{\tau^{\ast} = n + 1, X_{\tau^{\ast}} = j} = \sum_{k \in S - S^{\ast}} \probi{X_n = k, X_{n + 1} = j} = \sum_{k \in S - S^{\ast}} p_{i,k}^{(n)} p_{k,j}
\label{eq:tau-ast-nat}
\end{align}

Using that for $i$ to get absorbed by $j$ in time $n + 1$, one cannot go through a state in $S^{\ast}$ (otherwise absorption would happen). Also, using $p_{i,j}^{(0)} = \delta_{i,j}$, we have:

\begin{align}
\probi{\tau^{\ast} < \infty, X_{\tau^{\ast}} = j} = \sum_{n = 0}^{\infty} \sum_{k \in S - S^{\ast}} p_{i,k}^{(n)} p_{k,j} = \sum_{k \in S - S^{\ast}} \bigg(\delta_{i,k} + \expecti{V_k}\bigg) p_{k,j}
\label{eq:tau-ast-inf}
\end{align}

Let us note that this last equality is \eqref{prop:Fast-matrix} expressed matrix-wise.

To get \eqref{prop:fast-matrix}, it suffices to sum in $j \in S^{\ast}$ in Equation \eqref{eq:tau-ast-inf}.

Summing in $j \in S^{\ast}$ in \eqref{eq:tau-ast-nat} we arrive at:

\[
\probi{\tau^{\ast} = n + 1} \sum_{k \in S - S^{\ast}} p_{i,k}^{(n)} q_k = (B^n q)_i
\]
#+end_proof

#+begin_proposition
If $S - S^{\ast}$ is finite, the following relation holds:

\begin{align}
F^{\ast} = (I - W)^{-1} Q \\
f^{\ast} = 1
\end{align}

where the last equation tells us the absorption would take place almost surely.
#+end_proposition

#+begin_proof
It holds:
\[
(I + V)(I - W) = (I + W + W^2 + \ldots )(I - W) = I
\]
and therefore $(I + V) = (I - W)^{-1}$ (if we had not had finiteness we could not assure 
uniqueness for the inverse).

To check the other part, since the rows of the transition matrix from $S - S^{\ast}$ sum one,

\[
Q1_{S^{\ast}} + W 1_{S - S^{\ast}} = 1_{S - S^{\ast}} \dimplies Q1_{S^{\ast}} = (I - W) 1_{S - S^{\ast}}
\]

Therefore:

\[
f^{\ast} = F^{\ast} 1 = (I - W)^{-1} \cdot Q 1 = (I - B)^{-1}(I - B) 1_{S - S^{\ast}} = 1_{S - S^{\ast}}
\]

#+end_proof

#+begin_proposition
$F^{\ast}$ is the unique solution, with all its elements in $[0,1]$, of the system $(I-B)X = a$ iff 
absorption in $E^{\ast}$ is sure from every state in $E - E^{\ast}$.
#+end_proposition

#+begin_proof
Let us fix some $i \in E - E^{\ast}$, and assume $A >= B$ as a matrix iff:

\[
\sum_{i, j}{a_{i,j}} < \sum_{i, j}{b_{i,j}}
\]

From $(I - W) X = Q$ with $X$ with all its entries in $[0,1]$, we deduce:

\begin{align*}
X = Q + XW \ge Q \underset{X = Q + XW}{\implies} X \ge Q + QW \underset{X = Q + XW}{\implies} \\
X \ge Q + QW + AB^2 \implies \ldots \implies X \ge (I + V)Q = F^{\ast}
\end{align*}

Therefore $F^{\ast}$ is the minimum solution with entries in $[0,1]$ to the equation $(I - W)X = W$
and analogously $f^{\ast}$ is the minimum solution to $(I-B)x = a$.

On the one hand, if there exists solutions to $(I - W)X = Q$ with their elements on $[0,1]$ and not equal to $F^{\ast}$,
then $x = X 1$ would be solution to $(I - W)x = q$ and $f^{\ast} < x$ cannot be $1$.

On the other hand, if absorption is not sure, $x_i = 1 - f_i^{\ast}$ verify $x = Wx$. Therefore, $x = Bx$
has some non null solution, with $0 \le x \le 1$ and $X = F^{\ast} + x1$ is a solution for 
$(I - W)X = Q$ whose elements are in $[0,1]$, since:

\[
f_{i,j}^{\ast} + x_{i} = \probi{\tau^{\ast} < \infty, X_{\tau^{\infty}} = j} + \probi{\tau^{\ast} = \infty} \le \probi{\tau^{\ast} < \infty} + \probi{\tau^{\ast} = \infty} = 1
\]

#+end_proof

* =markovchain= package
We can propose an alternative definition of communicating property, taking $n \ge 0$ instead of $n > 0$, 
which has been the one used in the software from the start:

#+begin_definition
The state $i\in E$ communicates with $j\in S$, and we will write it like $i \rightarrow j$
iff $p_{i,j}^{(n)} > 0$ for some $n \ge 0$.
#+end_definition

Therefore, we can reformualte Proposition \eqref{prop:equiv-classes} as:

#+begin_proposition
$\dgoto$ is an equivalence relationship in $S^{\ast}$, and we can decompose:

\[
S = C_1 \cup C_2 \cup \ldots \cup C_r
\]

where for every $i, j \in C_k$, it holds $i \dgoto j$, and if $i \in C_k, j \in C_l$ where $k \neq l$, then $i \not\goto j$ or $j \not\goto i$.
#+end_proposition

The Corollary \eqref{corollary:comm-classes} is still valid with this definition, and gets used in the software.

With
* Bibliography
:PROPERTIES:
:UNNUMBERED: t
:END:
